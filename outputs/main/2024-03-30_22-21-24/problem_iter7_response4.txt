```python
import numpy as np

def select_next_node_v2(current_node: int, destination_node: int, unvisited_nodes: set, distance_matrix: np.ndarray) -> int:
    """Select the next node to visit from the unvisited nodes."""
    c1, c2, c3, c4 = 0.35, 0.25, 0.25, 0.15

    scores = {}
    for node in unvisited_nodes:
        distances_to_unvisited = distance_matrix[node, list(unvisited_nodes - {node})]
        average_distance_to_unvisited = np.mean(distances_to_unvisited)
        std_dev_distance_to_unvisited = np.std(distances_to_unvisited)
        # Adjusted weights for more effective decision-making
        score = c1 * distance_matrix[current_node, node] - c2 * average_distance_to_unvisited + c3 * std_dev_distance_to_unvisited - c4 * distance_matrix[destination_node, node]
        scores[node] = score

    next_node = min(scores, key=scores.get)
    return next_node
```
```

Explanation:
In this mutation, I made a few adjustments to the original code:

1. Adjusted the weights (c1, c2, c3, c4) to potentially improve the performance and the decision-making process. By incorporating domain knowledge and performing experiments, you can determine the best weights for your specific problem instance.

2. No unnecessary components were removed since the original code already focuses on the key factors for selecting the next node.

Overall, this mutation keeps the original structure intact while making adjustments to the weights for improved performance.
